# -*- coding: utf-8 -*-
"""AI4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17_E5KJeCn7xOP6UkKP_lNf3Sbn30_TH8
"""

'''!pip install ucimlrepo
!pip install patsy'''

import subprocess
packages_to_install = ['ucimlrepo', 'patsy']
for package in packages_to_install:
  subprocess.check_call(['pip', 'install', package])

from ucimlrepo import fetch_ucirepo
import numpy as np
import pandas as pd
import patsy
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt

abalone = fetch_ucirepo(id=1)
data = abalone.data.features
labels = abalone.data.targets

data['Sex'] = pd.Categorical(data['Sex'], categories=['M', 'F', 'I'], ordered=False)
helmert_encoded = patsy.dmatrix('Sex - 1', data=data, return_type='dataframe')
encoded_data = pd.concat([data, helmert_encoded], axis=1)
encoded_data = encoded_data.drop('Sex', axis=1)

from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(encoded_data, labels, test_size=0.2, random_state=42)

# Apply polynomial transformation
degree = 2
poly = PolynomialFeatures(degree)
X_train = poly.fit_transform(X_train)
X_test = poly.transform(X_test)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train linear regression model on polynomial features
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions on the test set
y_pred = model.predict(X_test)
score_linear_regression = r2_score(y_test, y_pred)

from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.pipeline import make_pipeline


# Create a pipeline with standardization and Ridge regression
model = make_pipeline(StandardScaler(), PolynomialFeatures(2),Ridge(alpha=3.0))
model.fit(encoded_data, labels)

y_pred = model.predict(encoded_data)

# Evaluate the model
final_r2 = r2_score(labels, y_pred)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import make_pipeline
import matplotlib.pyplot as plt


num_iterations = 20

# Initialize an array to store R2 scores
r2_scores = []

for _ in range(num_iterations):
    # Split the data into train and test sets (70% train, 15% validation, 15% test)
    X_train, X_temp, y_train, y_temp = train_test_split(encoded_data, labels, test_size=0.3, random_state=np.random.randint(1, 1000))
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=np.random.randint(1, 1000))

    # Evaluate the model on the validation set
    r2 = model.score(X_val, y_val)
    r2_scores.append(r2)

# Calculate the average and standard deviation of R2 scores
average_r2 = np.mean(r2_scores)
std_dev_r2 = np.std(r2_scores)


# Plot the box plot
plt.boxplot(r2_scores)
plt.title('Box Plot of R2 Scores')
plt.ylabel('R2 Score')
plt.show()

print(f"Full dataset train and eval R2 score: {final_r2:.2f}")
print(f"70-15-15 Cross validation boxplot: mean={average_r2:.2f}, std={std_dev_r2:.2f}")